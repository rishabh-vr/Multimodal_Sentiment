{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ2i5wJ4QtJ2",
        "outputId": "11b9151a-9103-4d44-8622-bebb408a64ab"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from transformers import AutoModel, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1P-aFO0SGsAG"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/Users/sahil/Programs/projects/MSA/Datasets/IMDB Dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "DWjbDzm4Qj0I",
        "outputId": "f6845533-fa49-4d93-8160-4672deac859c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment\n",
              "positive    25000\n",
              "negative    25000\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "F0Vp_UGZQn-O",
        "outputId": "ee382ca7-e793-49e1-a9c0-147cd2d310c8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "label_counts = df['sentiment'].value_counts(ascending=True)\n",
        "label_counts.plot.barh()\n",
        "plt.title(\"Frequency of Classes\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "IH50VTcyQz0s",
        "outputId": "f7e33668-6351-4ce6-957b-174acf492e2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: title={'center': 'Words per review'}, xlabel='sentiment'>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df['Words per review'] = df['review'].str.split().apply(len)\n",
        "df.boxplot(\"Words per review\", by=\"sentiment\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA9ixGLlQ2nD",
        "outputId": "2d69db73-e467-41e5-fc2c-ea449f719666"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': [101, 2057, 2293, 2000, 3637, 999, 12214, 2024, 12476, 999, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(30522, 30522, 512)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_ckpt = \"distilbert-base-uncased\"  #ENGLISH english\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "text = \"We love to sleep! Winters are awesome!\"\n",
        "encoded_text = tokenizer(text)\n",
        "print(encoded_text)\n",
        "len(tokenizer.vocab),tokenizer.vocab_size, tokenizer.model_max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LpMWujERBIJ",
        "outputId": "92e62598-2471-4935-a166-f510536ff1e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((35000, 3), (10000, 3), (5000, 3))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df, test_size=0.3, stratify=df['sentiment'])\n",
        "test, validation = train_test_split(test, test_size=1/3, stratify=test['sentiment'])\n",
        "train.shape, test.shape, validation.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "olYHrfUTROsr"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "dataset = DatasetDict({\n",
        "    \"train\": Dataset.from_pandas(train, preserve_index=False),\n",
        "    \"test\": Dataset.from_pandas(test, preserve_index=False),\n",
        "    \"validation\": Dataset.from_pandas(validation, preserve_index=False)\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH_fLAihRp7Y",
        "outputId": "f9b40809-5bad-46dd-dfeb-365c959167dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['review', 'sentiment', 'Words per review'],\n",
              "        num_rows: 35000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['review', 'sentiment', 'Words per review'],\n",
              "        num_rows: 10000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['review', 'sentiment', 'Words per review'],\n",
              "        num_rows: 5000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKPPHiW8RsHA",
        "outputId": "f4434bd0-049e-4e7b-eff9-04d19aaa0ab9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['review', 'sentiment', 'Words per review'],\n",
              "    num_rows: 35000\n",
              "})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWThmW8yRu69",
        "outputId": "85395df1-a195-4538-cfbe-4de40a3d93a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': [[101, 2070, 2025, 1011, 2061, 1011, 27594, 2100, 27594, 2545, 3805, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2339, 2079, 2111, 1010, 2043, 2027, 2024, 4487, 21748, 25099, 2094, 2030, 5305, 2030, 6015, 2012, 1037, 2252, 1010, 3013, 2083, 1996, 2690, 1997, 1996, 10789, 3153, 2723, 2006, 2037, 2126, 2000, 1996, 5723, 1029, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2040, 1999, 2037, 2157, 2568, 2052, 5342, 2104, 1037, 2793, 2043, 2619, 7807, 2046, 2037, 2282, 1029, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2129, 2411, 2079, 2017, 7324, 2006, 1037, 7985, 1005, 1055, 2341, 1998, 2043, 2027, 2123, 1005, 1056, 3202, 3437, 1010, 2017, 2330, 1996, 2341, 1010, 3328, 1999, 1010, 11245, 1037, 2261, 7592, 1005, 1055, 1998, 2059, 2707, 2183, 2083, 2037, 4933, 1029, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2065, 2017, 2020, 2108, 9505, 2011, 2619, 2017, 2074, 3603, 2001, 1037, 13422, 1010, 2054, 2052, 2017, 2079, 1029, 5168, 13583, 2125, 1998, 5342, 2104, 1037, 4799, 4132, 2030, 2426, 3384, 22164, 1029, 2448, 1010, 5168, 1997, 2607, 1010, 2000, 1037, 9350, 3723, 2214, 8659, 2030, 2060, 11703, 2890, 23270, 3252, 1029, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1045, 2071, 2022, 3331, 2055, 2471, 2151, 10874, 2008, 1005, 1055, 2272, 2041, 1999, 1996, 2197, 2261, 2086, 1010, 2021, 2144, 2023, 2003, 1996, 1000, 1996, 2709, 1000, 3931, 1010, 5525, 1045, 1005, 1049, 3331, 2055, 1000, 1996, 2709, 1012, 1000, 1045, 2387, 2009, 2489, 2138, 1045, 2147, 2012, 1037, 3185, 4258, 1998, 2191, 1037, 2391, 1997, 11326, 2035, 1996, 1000, 12459, 1000, 5691, 1012, 1045, 2245, 2023, 2028, 2001, 2000, 3917, 3085, 1012, 1012, 1012, 4998, 2013, 1996, 2092, 1011, 6247, 18856, 17322, 2015, 1012, 4532, 9393, 21500, 8017, 2003, 2428, 2852, 7875, 1998, 3504, 2785, 1997, 1000, 9616, 1029, 1000, 2083, 2087, 1997, 1996, 2143, 1012, 1996, 4751, 1997, 1996, 5436, 2024, 3254, 2445, 2041, 2004, 1996, 3185, 22901, 1998, 2009, 1005, 1055, 2471, 2438, 2000, 2191, 2009, 5875, 3272, 2045, 2347, 1005, 1056, 2438, 7526, 2004, 2009, 2333, 2006, 1998, 2061, 1045, 2001, 2471, 2439, 2127, 1996, 2197, 1016, 1013, 1017, 1997, 2009, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2065, 2017, 1005, 2128, 1037, 3280, 1011, 2524, 10874, 5470, 1010, 2009, 1005, 1055, 4276, 3773, 2012, 2560, 2320, 1012, 2065, 2045, 1005, 1055, 2498, 2488, 2012, 1996, 4258, 1998, 2017, 2428, 2215, 2000, 3422, 1037, 3185, 1010, 15501, 1010, 1045, 3984, 2009, 1005, 1055, 4276, 1037, 13523, 3170, 2063, 7281, 1012, 2065, 2017, 2245, 1996, 9117, 2081, 2009, 2298, 2066, 2019, 5875, 3185, 1998, 2017, 2064, 1005, 1056, 3524, 1012, 1012, 1012, 3524, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2379, 1996, 5494, 5711, 1997, 3336, 9588, 1010, 2028, 1997, 1996, 2430, 3494, 3632, 2006, 2000, 6235, 1996, 3937, 12685, 1997, 2673, 2008, 2234, 2077, 1998, 7680, 7849, 13087, 2008, 2009, 1005, 2001, 2035, 2074, 1037, 6752, 1005, 1025, 1045, 2428, 2481, 1005, 1056, 2360, 2009, 2151, 2488, 2084, 2008, 1012, 1998, 2096, 1996, 3444, 2515, 2031, 2049, 5976, 4097, 1997, 3246, 2296, 2085, 1998, 2153, 1010, 1996, 6565, 3484, 1997, 2054, 2003, 2556, 2003, 2205, 11265, 19901, 2098, 2000, 2022, 2641, 7882, 1998, 2205, 4895, 28578, 17007, 3085, 2000, 2022, 4276, 3087, 1005, 1055, 2051, 1012, 1037, 3768, 7393, 7913, 3459, 1010, 24684, 5896, 1998, 13727, 1010, 2482, 5555, 11244, 3494, 5676, 2008, 3336, 9588, 5121, 3475, 1005, 1056, 10095, 3070, 2006, 1996, 19330, 1005, 2053, 13871, 2378, 1010, 2021, 2009, 2196, 3084, 2039, 2005, 2023, 2083, 2049, 3818, 3168, 1997, 17211, 1012, 5398, 3701, 1997, 2200, 9410, 1010, 18856, 17322, 13198, 2241, 2105, 2019, 5976, 3232, 1006, 4138, 1998, 3532, 1007, 2667, 2000, 2444, 2007, 2169, 2060, 2004, 2027, 7374, 2000, 3288, 1037, 3336, 2046, 1996, 2088, 1010, 1996, 2143, 2003, 2521, 2205, 9686, 29112, 2000, 8116, 11680, 2648, 2049, 2200, 4857, 15982, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2004, 1037, 2466, 2006, 4531, 2293, 1010, 2009, 1005, 1055, 2025, 2008, 2919, 1010, 2021, 2652, 2023, 5436, 2240, 2004, 1037, 2217, 1011, 2466, 1997, 11901, 2000, 2147, 4077, 1996, 4038, 1011, 16865, 4383, 5976, 3232, 27250, 1010, 2839, 6648, 2003, 5546, 5410, 1010, 4525, 1999, 1037, 5355, 9028, 2213, 7472, 2008, 2196, 17255, 1012, 2004, 3494, 3209, 1010, 2119, 2430, 4481, 2024, 19499, 19142, 2043, 2404, 2362, 1999, 2235, 7258, 1010, 2021, 2043, 2187, 2894, 2855, 4895, 22401, 2140, 1998, 6436, 2037, 23397, 1025, 2061, 2096, 2057, 2089, 2776, 2272, 2000, 2424, 1996, 2839, 1005, 1055, 10266, 2007, 2169, 2060, 19142, 2012, 2335, 1010, 1996, 4038, 2196, 5628, 3458, 6802, 26088, 1025, 2057, 2123, 1005, 1056, 2514, 2005, 1996, 3494, 1998, 2123, 1005, 1056, 2424, 2068, 26096, 5875, 1010, 2021, 2738, 2037, 8790, 1012, 6854, 2174, 1010, 2348, 2023, 8790, 2573, 2190, 1010, 2030, 2012, 2560, 2488, 2084, 1996, 3265, 16115, 2015, 1010, 2004, 3855, 2682, 1010, 2009, 6524, 12402, 2648, 1997, 1996, 5171, 25722, 1997, 1996, 5976, 1011, 3232, 5675, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 5736, 1006, 11958, 23864, 1007, 2003, 1037, 3144, 2449, 2450, 2040, 2038, 5086, 2551, 2465, 1010, 12873, 1011, 9081, 14835, 1006, 6864, 18922, 13620, 1007, 2000, 2022, 2014, 9832, 7505, 21799, 1010, 1998, 2044, 14835, 7288, 2000, 2681, 20625, 3129, 5529, 1006, 27116, 22189, 1007, 1010, 2119, 2776, 2031, 2000, 4553, 2000, 2444, 2362, 2750, 2037, 5793, 5966, 1012, 2748, 1010, 2009, 1005, 1055, 1996, 5171, 5976, 1011, 3232, 18458, 1010, 1998, 2028, 2008, 2057, 2031, 2525, 2464, 1999, 2023, 2095, 1005, 1055, 2054, 6433, 1999, 7136, 1010, 2664, 2054, 3336, 9588, 14087, 2008, 1996, 17289, 3185, 2018, 2003, 2119, 6370, 2090, 9567, 1998, 4100, 1011, 21323, 3494, 1012, 5736, 1998, 14835, 2119, 8246, 2000, 2412, 2265, 2172, 1997, 1037, 6180, 2648, 1997, 2037, 2048, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [0, 0]}\n"
          ]
        }
      ],
      "source": [
        "def tokenize(batch):\n",
        "    # Tokenize text with padding and truncation\n",
        "    temp = tokenizer(batch['review'], padding=True, truncation=True, return_token_type_ids=True)\n",
        "\n",
        "    # Convert sentiment from strings (\"positive\"/\"negative\") to integers (1/0)\n",
        "    temp['labels'] = [1 if sentiment == 'positive' else 0 for sentiment in batch['sentiment']]\n",
        "\n",
        "    return temp\n",
        "\n",
        "print(tokenize(dataset['train'][:2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "805fc0b3514a48a8811fc5ad229f87aa",
            "5f98a7d1a14749e4abcd84bd28cafe59",
            "bec587eadac44b07866904a981251210",
            "596b48836576428ca40560e7f929b714",
            "913e29c4bdc84de2be0fb22739ba3477",
            "ce54aca5b5e3479c8757f82e65369c79",
            "d4749681d1e54c6daffeaf0b977dfbde",
            "9f7996cdd55e400ba9a9ad6652b551b9",
            "954a1e50c02644ddb173bd08c0dff0f6",
            "9a8973980d9146828d52e5a1b3cbac9e",
            "ab8b099771cb4308b45fb68400842b14",
            "5c9b2069c2944482b266e9978b446a7d",
            "07a6c9c54b0f4c1089ac3c2cb4a0a3de",
            "d03e1b7428924223989a4165677942c6",
            "df86635c6c114aa18764faaa03a8a321",
            "8df3aa8f8f094a0c857a596a2cc61e84",
            "68ced9ee07664ae3bdd7e7952d098f7b",
            "0027ab7df76e4434af60ec9a53ba8a45",
            "ad856b0331c44d8387d3fe3959022047",
            "675bd947ecfc4e3c865d316a9ce9a448",
            "427a50b2b4a74b61b45d8d8b05b5d3ad",
            "6f48f6474c2f4a6ebf88ae8258ea6d94",
            "381e37e909ce4b9dad342e0d496b0b35",
            "75bb5e0ea62f43bf87b961c6d6499c95",
            "048c7f91bc274f8bb0ec7a69533739a6",
            "3e5f83568dbf4e9a854b5cf28e90fccf",
            "022f5dae33c14d0f877912a5dbbe13b0",
            "58a5ac485ab8430b800e7074514a20f9",
            "96b6d705b60c43f2881f67e3eba2f9c4",
            "904cd907b85749f48e50ed8595c19342",
            "ffd6b6f83e3543419902fa503e8840ab",
            "b3fd3ebca83a454b9084de729b6ca644",
            "1b999f2e4f23449c8e9ecd68a04c927a"
          ]
        },
        "id": "RyNyWZozRyJe",
        "outputId": "4ac55fcd-1849-434d-b884-526615209905"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cdb71dfc092647fd854c91ab0eff535c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/35000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efe67a4ac6b840bc9852284a9e1b2b0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f323f297820a4d7db844892bfcc1def1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "emotion_encoded=dataset.map(tokenize, batched=True, batch_size=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAM6q5KER3xg",
        "outputId": "85df3069-8ba6-4168-cac6-da138b7353aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['positive', 'negative'],\n",
              " {0: 'positive', 1: 'negative'},\n",
              " {'positive': 0, 'negative': 1})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment_id = list({x['sentiment'] for x in dataset ['train']})\n",
        "id2label = {id:label for id, label in enumerate(sentiment_id)}\n",
        "label2id = {label:id for id, label in id2label.items()}\n",
        "sentiment_id, id2label, label2id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5s3HlZggULDL"
      },
      "outputs": [],
      "source": [
        "model= AutoModel.from_pretrained(model_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CLmUqLFpUpsC"
      },
      "outputs": [],
      "source": [
        "model.config\n",
        "model_two=\"bert-base-cased\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Nqe_GkcU54N",
        "outputId": "fd5f5d72-1757-42e6-fe11-e217d2c343ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoConfig\n",
        "Num_labels = len(label2id)\n",
        "device = torch.device (\"cuda\" if torch. cuda.is_available() else \"cpu\")\n",
        "config = AutoConfig.from_pretrained(model_ckpt, label2id=label2id, id2label=id2label)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, config=config).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHE00VfbU9XD",
        "outputId": "65448d44-ca26-4cb8-e103-b3545880f345"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wktXTkdteDYY",
        "outputId": "0675d46d-bc11-4ebe-982d-72b2c09355ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHDw1RYPVBI1",
        "outputId": "8d22da8d-2e94-45b8-db4a-bb3819a1183a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sahil/miniconda3/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments\n",
        "batch_size=2\n",
        "training_dir = \"bert_base_training_dir\"\n",
        "training_args= TrainingArguments(output_dir = training_dir,\n",
        "              overwrite_output_dir = True,\n",
        "              num_train_epochs = 2,\n",
        "              learning_rate = 2e-5,\n",
        "              per_device_train_batch_size = batch_size,\n",
        "              per_device_eval_batch_size = batch_size,\n",
        "              weight_decay = 0.01,\n",
        "              evaluation_strategy = 'epoch',\n",
        "              disable_tqdm = False\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRhsucOzVXoZ",
        "outputId": "ad89a7bb-cbdb-4745-d76d-935fb66f7018"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'compute_metrics' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[23], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[1;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      3\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      4\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m      5\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39memotion_encoded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      6\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39memotion_encoded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m----> 7\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39m\u001b[43mcompute_metrics\u001b[49m,\n\u001b[1;32m      8\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer\n\u001b[1;32m      9\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'compute_metrics' is not defined"
          ]
        }
      ],
      "source": [
        "from transformers import Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=emotion_encoded['train'],\n",
        "    eval_dataset=emotion_encoded['validation'],\n",
        "    tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "# Replace your API key inside the quotes\n",
        "wandb.login(key=\"40907ad1b0fee06461600d6cd5c0798707707d2e\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='35000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [    2/35000 : < :, Epoch 0.00/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2172\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/trainer.py:2531\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2524\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2525\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2528\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2529\u001b[0m )\n\u001b[1;32m   2530\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2531\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2534\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2535\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2536\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2537\u001b[0m ):\n\u001b[1;32m   2538\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2539\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/trainer.py:3715\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_items_in_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3713\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n\u001b[0;32m-> 3715\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3717\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/accelerate/accelerator.py:2246\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2245\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2246\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.model_save(\"MSA_bert_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_to_model='/Users/sahil/Programs/projects/MSA/model'\n",
        "tuned_model = AutoModelForSequenceClassification.from_pretrained(path_to_model)\n",
        "tuned_tokenizer = AutoTokenizer.from_pretrained(path_to_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Label: positive (Probability: 0.8825)\n"
          ]
        }
      ],
      "source": [
        "text = \"The movie was like sweet candy.\"\n",
        "inputs=tuned_tokenizer(text=text)\n",
        "inputs = tuned_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "with torch.no_grad():\n",
        "    outputs = tuned_model(**inputs)\n",
        "\n",
        "logits = outputs.logits\n",
        "probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "\n",
        "predicted_label = torch.argmax(probabilities, dim=-1).item()\n",
        "label_map = {0: \"negative\", 1: \"positive\"}  \n",
        "print(f\"Predicted Label: {label_map[predicted_label]} (Probability: {probabilities[0, predicted_label].item():.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "HFcanx6hj1Y0"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    emotion_encoded['train'],\n",
        "    batch_size=32,  # Increase this from 1\n",
        "    shuffle=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "V8ThAnGuj3SL"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm  # For the progress bar\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First batch structure:\n",
            "review: <class 'list'>\n",
            "Shape/Length: 32\n",
            "sentiment: <class 'list'>\n",
            "Shape/Length: 32\n",
            "Words per review: <class 'torch.Tensor'>\n",
            "Shape/Length: 32\n",
            "input_ids: <class 'list'>\n",
            "Shape/Length: 512\n",
            "token_type_ids: <class 'list'>\n",
            "Shape/Length: 512\n",
            "attention_mask: <class 'list'>\n",
            "Shape/Length: 512\n",
            "labels: <class 'torch.Tensor'>\n",
            "Shape/Length: 32\n",
            "\n",
            "Labels structure:\n",
            "Type: <class 'datasets.arrow_dataset.Dataset'>\n",
            "Shape/Length: 10000\n",
            "First few labels: {'review': [\"Good Movie, acting was terrific especially from Eriq Ebouaney(Lumumba)and very well directed.<br /><br />It also shows how Lumumba was cornered by the Belgians, U S A and United Nations and how they labelled him a `communist' to scare people as they did to all the Honest True African leaders like Nkrumah, Kenyatta, Nyerere and many others. It shows how western countries preach democracy while they have something else on the back of their minds. It is a story of injustice, struggle and brutality.<br /><br />It shows how Lumumba couldn't control his people, yes they were his people, but before we put the blame on him, was he getting enough if any from the people he appointed in his government like Mobutu? Or his colleague had other things in their minds, to find out go and see the movie! Certainly Mobutu did, went on to loot the country for the next 35 yrs, before he was overthrown and fled the country. Died a billionaire.<br /><br />Some flaws: There was too little explanation how the man (Lumumba) got to rise in the first place. Also there should have been more explanation about the country, Congo Kinshasa (after independence), now known as Democratic Republic of Congo formerly known as Zaire when it was under Mobutu. There should have been an explanation why he (Lumumba) couldn't keep the second largest country in Africa in one piece. And also what was going on with Tshombe and Katanga . Just heads up if you gonna watch the movie Tshombe was controlling the Katanga region which (if I am not mistaken) is the number one copper producer in the world.<br /><br />In all it is a good movie to see. You will learn something new about Africa, it's leaders and it's people and probably will open your eyes why this continent is ridden with wars.\", 'Despite the all-star cast, this attempt at epic fails. It comes across as a set of flat cartoon stereotypes strung together by an all too, too clever social commentary. <br /><br />It\\'s as if with every bit of dialogue and introduction to a new character the writer peeks out and says \"Isn\\'t that clever? Am I not smart? Isn\\'t that biting social commentary?\" And,sadly, the answer is always \"Ummmm...no.\" Wearying self-absorbing stuff that is more like soap opera (in the worst sense of the term) than a movie...and an obvious attempt at television immortality. Thankfully, it died young. Empire Falls falls flat.', 'This film plunges headlong into the realm of the surreal à la Lynch and Jodorowsky--with an atmosphere that is strangely compelling, lulling the viewer with the dream-like intensity of its images.<br /><br />The narration is to be savoured--the narrator being trapped behind a painting (adjacent to the bed), who often speaks for it, vocalizing its desires and reasoning. Yes, Beardsley would sound like that.<br /><br />There are some flaws, but its strengths overwhelm its weaknesses. The sequence with the woman wrenching herself out of the bed and crawling across the floor, trying to escape, will leave you breathless. <br /><br />The film possesses a fin-de-siecle air about it; and should be read as a disarming cry from the bowels of the 20th century.<br /><br />Find this film and bathe in it.', 'This film is truly pathetic in every conceivable department. awful, awful, awful. It\\'s only around eighty minutes long, but believe me you\\'ll feel like you\\'re watching an Andy Warhol film (then again twenty hours in the life of the empire state building would surely be far more interesting).<br /><br />Where to start... the putrid script, the disgusting cinematography, the so bad its bad acting, the spectacularly dismal effects, dreadful music, or just the wafer thin plot that thouroughly resembles a sieve. This film is an incoherent shambles<br /><br />A particularly noteworthy scene takes place outside a cafe when Dominic Pinon decides to shoot a cat, cue the waitress watching through the cafe window who comments with an average English accent \"God damn\". To right that woman. God damn this horrendous monstrosity.<br /><br />Everyone involved should be thouroughly ashamed of themselves. Let us hope that the director never finds the funding to work again.', \"I love Columbo and have seen pretty much all of the episodes but this one undoubtedly ranks as the worst of the lot. A mind-bogglingly tedious, pointless, muddled pile of unwatchable drivel that wastes both the time of the viewing audience and of the acting talents of an exceedingly bored-looking Peter Falk. The 'plot', such as it is, just seems to be made up as the film goes along with not even the slightest hint of the ingredients to the formula that made the show such a brilliant success to start with. One part of the proceedings which I found extremely puzzling ( or possibly annoying ) was Peter Falk's character being introduced to the guests at the wedding as 'Lt' Columbo. If the producers insist on keeping Columbo's first name a secret, why couldn't they have omitted this line altogether as it sounds ridiculous? Like I said, this is the pits and all true Columbo fans would do well to avoid it like the plague.\"], 'sentiment': ['positive', 'negative', 'positive', 'negative', 'negative'], 'Words per review': [308, 102, 131, 153, 166], 'input_ids': [[101, 2204, 3185, 1010, 3772, 2001, 27547, 2926, 2013, 9413, 18515, 1041, 5092, 13860, 3240, 1006, 11320, 27147, 3676, 1007, 1998, 2200, 2092, 2856, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2009, 2036, 3065, 2129, 11320, 27147, 3676, 2001, 25878, 2011, 1996, 6995, 2015, 1010, 1057, 1055, 1037, 1998, 2142, 3741, 1998, 2129, 2027, 18251, 2032, 1037, 1036, 4750, 1005, 2000, 12665, 2111, 2004, 2027, 2106, 2000, 2035, 1996, 7481, 2995, 3060, 4177, 2066, 25930, 6824, 4430, 1010, 7938, 5946, 1010, 6396, 7869, 2890, 1998, 2116, 2500, 1012, 2009, 3065, 2129, 2530, 3032, 25250, 7072, 2096, 2027, 2031, 2242, 2842, 2006, 1996, 2067, 1997, 2037, 9273, 1012, 2009, 2003, 1037, 2466, 1997, 21321, 1010, 5998, 1998, 24083, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2009, 3065, 2129, 11320, 27147, 3676, 2481, 1005, 1056, 2491, 2010, 2111, 1010, 2748, 2027, 2020, 2010, 2111, 1010, 2021, 2077, 2057, 2404, 1996, 7499, 2006, 2032, 1010, 2001, 2002, 2893, 2438, 2065, 2151, 2013, 1996, 2111, 2002, 2805, 1999, 2010, 2231, 2066, 11240, 4904, 2226, 1029, 2030, 2010, 11729, 2018, 2060, 2477, 1999, 2037, 9273, 1010, 2000, 2424, 2041, 2175, 1998, 2156, 1996, 3185, 999, 5121, 11240, 4904, 2226, 2106, 1010, 2253, 2006, 2000, 8840, 4140, 1996, 2406, 2005, 1996, 2279, 3486, 1061, 2869, 1010, 2077, 2002, 2001, 16857, 2078, 1998, 6783, 1996, 2406, 1012, 2351, 1037, 22301, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2070, 21407, 1024, 2045, 2001, 2205, 2210, 7526, 2129, 1996, 2158, 1006, 11320, 27147, 3676, 1007, 2288, 2000, 4125, 1999, 1996, 2034, 2173, 1012, 2036, 2045, 2323, 2031, 2042, 2062, 7526, 2055, 1996, 2406, 1010, 9030, 12631, 7377, 3736, 1006, 2044, 4336, 1007, 1010, 2085, 2124, 2004, 3537, 3072, 1997, 9030, 3839, 2124, 2004, 23564, 7442, 2043, 2009, 2001, 2104, 11240, 4904, 2226, 1012, 2045, 2323, 2031, 2042, 2019, 7526, 2339, 2002, 1006, 11320, 27147, 3676, 1007, 2481, 1005, 1056, 2562, 1996, 2117, 2922, 2406, 1999, 3088, 1999, 2028, 3538, 1012, 1998, 2036, 2054, 2001, 2183, 2006, 2007, 24529, 23393, 4783, 1998, 29354, 13807, 1012, 2074, 4641, 2039, 2065, 2017, 6069, 3422, 1996, 3185, 24529, 23393, 4783, 2001, 9756, 1996, 29354, 13807, 2555, 2029, 1006, 2065, 1045, 2572, 2025, 13534, 1007, 2003, 1996, 2193, 2028, 6967, 3135, 1999, 1996, 2088, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1999, 2035, 2009, 2003, 1037, 2204, 3185, 2000, 2156, 1012, 2017, 2097, 4553, 2242, 2047, 2055, 3088, 1010, 2009, 1005, 1055, 4177, 1998, 2009, 1005, 1055, 2111, 1998, 2763, 2097, 2330, 2115, 2159, 2339, 2023, 9983, 2003, 15230, 2007, 5233, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2750, 1996, 2035, 1011, 2732, 3459, 1010, 2023, 3535, 2012, 8680, 11896, 1012, 2009, 3310, 2408, 2004, 1037, 2275, 1997, 4257, 9476, 22807, 23509, 2362, 2011, 2019, 2035, 2205, 1010, 2205, 12266, 2591, 8570, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2009, 1005, 1055, 2004, 2065, 2007, 2296, 2978, 1997, 7982, 1998, 4955, 2000, 1037, 2047, 2839, 1996, 3213, 19043, 2015, 2041, 1998, 2758, 1000, 3475, 1005, 1056, 2008, 12266, 1029, 2572, 1045, 2025, 6047, 1029, 3475, 1005, 1056, 2008, 12344, 2591, 8570, 1029, 1000, 1998, 1010, 13718, 1010, 1996, 3437, 2003, 2467, 1000, 26114, 7382, 1012, 1012, 1012, 2053, 1012, 1000, 16040, 2075, 2969, 1011, 20998, 4933, 2008, 2003, 2062, 2066, 7815, 3850, 1006, 1999, 1996, 5409, 3168, 1997, 1996, 2744, 1007, 2084, 1037, 3185, 1012, 1012, 1012, 1998, 2019, 5793, 3535, 2012, 2547, 20107, 1012, 16047, 1010, 2009, 2351, 2402, 1012, 3400, 4212, 4212, 4257, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2023, 2143, 25912, 2015, 2132, 10052, 2046, 1996, 8391, 1997, 1996, 16524, 1037, 2474, 11404, 1998, 8183, 7983, 15568, 4801, 1011, 1011, 2007, 2019, 7224, 2008, 2003, 13939, 17075, 1010, 11320, 13112, 1996, 13972, 2007, 1996, 3959, 1011, 2066, 8015, 1997, 2049, 4871, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 21283, 2003, 2000, 2022, 7842, 6767, 12165, 1011, 1011, 1996, 11185, 2108, 7567, 2369, 1037, 4169, 1006, 5516, 2000, 1996, 2793, 1007, 1010, 2040, 2411, 8847, 2005, 2009, 1010, 5554, 6026, 2049, 14714, 1998, 13384, 1012, 2748, 1010, 10154, 8002, 2052, 2614, 2066, 2008, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2045, 2024, 2070, 21407, 1010, 2021, 2049, 20828, 2058, 2860, 24546, 2049, 21775, 1012, 1996, 5537, 2007, 1996, 2450, 16255, 8450, 2841, 2041, 1997, 1996, 2793, 1998, 15927, 2408, 1996, 2723, 1010, 2667, 2000, 4019, 1010, 2097, 2681, 2017, 16701, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 2143, 14882, 1037, 10346, 1011, 2139, 1011, 9033, 8586, 2571, 2250, 2055, 2009, 1025, 1998, 2323, 2022, 3191, 2004, 1037, 4487, 10286, 6562, 5390, 2013, 1996, 6812, 9050, 1997, 1996, 3983, 2301, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2424, 2023, 2143, 1998, 7198, 2063, 1999, 2009, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2023, 2143, 2003, 5621, 17203, 1999, 2296, 9530, 3401, 11444, 3468, 2533, 1012, 9643, 1010, 9643, 1010, 9643, 1012, 2009, 1005, 1055, 2069, 2105, 12021, 2781, 2146, 1010, 2021, 2903, 2033, 2017, 1005, 2222, 2514, 2066, 2017, 1005, 2128, 3666, 2019, 5557, 2162, 14854, 2143, 1006, 2059, 2153, 3174, 2847, 1999, 1996, 2166, 1997, 1996, 3400, 2110, 2311, 2052, 7543, 2022, 2521, 2062, 5875, 1007, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2073, 2000, 2707, 1012, 1012, 1012, 1996, 2404, 14615, 5896, 1010, 1996, 19424, 16434, 1010, 1996, 2061, 2919, 2049, 2919, 3772, 1010, 1996, 12656, 2135, 4487, 26212, 2140, 3896, 1010, 21794, 2189, 1010, 2030, 2074, 1996, 11333, 7512, 4857, 5436, 2008, 15223, 22494, 5603, 2135, 12950, 1037, 9033, 18697, 1012, 2023, 2143, 2003, 2019, 4297, 11631, 7869, 3372, 25850, 13510, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1037, 3391, 19144, 3496, 3138, 2173, 2648, 1037, 7668, 2043, 11282, 9231, 2239, 7288, 2000, 5607, 1037, 4937, 1010, 16091, 1996, 13877, 3666, 2083, 1996, 7668, 3332, 2040, 7928, 2007, 2019, 2779, 2394, 9669, 1000, 2643, 4365, 1000, 1012, 2000, 2157, 2008, 2450, 1012, 2643, 4365, 2023, 7570, 14343, 15482, 2271, 29408, 13181, 17759, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 3071, 2920, 2323, 2022, 15223, 22494, 5603, 2135, 14984, 1997, 3209, 1012, 2292, 2149, 3246, 2008, 1996, 2472, 2196, 4858, 1996, 4804, 2000, 2147, 2153, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1045, 2293, 8902, 25438, 2080, 1998, 2031, 2464, 3492, 2172, 2035, 1997, 1996, 4178, 2021, 2023, 2028, 17319, 6938, 2004, 1996, 5409, 1997, 1996, 2843, 1012, 1037, 2568, 1011, 22132, 18483, 2135, 6945, 6313, 1010, 23100, 1010, 8494, 20043, 8632, 1997, 4895, 18866, 3085, 3298, 2140, 2008, 5949, 2015, 2119, 1996, 2051, 1997, 1996, 10523, 4378, 1998, 1997, 1996, 3772, 11725, 1997, 2019, 17003, 2135, 11471, 1011, 2559, 2848, 6904, 13687, 1012, 1996, 1005, 5436, 1005, 1010, 2107, 2004, 2009, 2003, 1010, 2074, 3849, 2000, 2022, 2081, 2039, 2004, 1996, 2143, 3632, 2247, 2007, 2025, 2130, 1996, 15989, 9374, 1997, 1996, 12760, 2000, 1996, 5675, 2008, 2081, 1996, 2265, 2107, 1037, 8235, 3112, 2000, 2707, 2007, 1012, 2028, 2112, 1997, 1996, 8931, 2029, 1045, 2179, 5186, 16405, 20838, 1006, 2030, 4298, 15703, 1007, 2001, 2848, 6904, 13687, 1005, 1055, 2839, 2108, 3107, 2000, 1996, 6368, 2012, 1996, 5030, 2004, 1005, 8318, 1005, 8902, 25438, 2080, 1012, 2065, 1996, 6443, 18292, 2006, 4363, 8902, 25438, 2080, 1005, 1055, 2034, 2171, 1037, 3595, 1010, 2339, 2481, 1005, 1056, 2027, 2031, 16647, 2023, 2240, 10462, 2004, 2009, 4165, 9951, 1029, 2066, 1045, 2056, 1010, 2023, 2003, 1996, 14496, 1998, 2035, 2995, 8902, 25438, 2080, 4599, 2052, 2079, 2092, 2000, 4468, 2009, 2066, 1996, 11629, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'labels': [1, 0, 1, 0, 0]}\n"
          ]
        }
      ],
      "source": [
        "# Add this before your accuracy calculation\n",
        "print(\"First batch structure:\")\n",
        "batch = next(iter(test_dataloader))\n",
        "for key in batch:\n",
        "    print(f\"{key}: {type(batch[key])}\")\n",
        "    print(f\"Shape/Length: {len(batch[key])}\")\n",
        "\n",
        "print(\"\\nLabels structure:\")\n",
        "print(f\"Type: {type(emotion_encoded['test'])}\")\n",
        "print(f\"Shape/Length: {len(emotion_encoded['test'])}\")\n",
        "print(f\"First few labels: {emotion_encoded['test'][:5]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/37/x82lvgr524l4fd08t3g06rl40000gn/T/ipykernel_20874/1704487477.py:7: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
            "  device = device or (\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.has_mps else \"cpu\")\n",
            "Evaluating Accuracy:   0%|          | 0/1094 [00:00<?, ?it/s]/var/folders/37/x82lvgr524l4fd08t3g06rl40000gn/T/ipykernel_20874/1704487477.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input_ids = torch.stack([torch.tensor(item) for item in batch['input_ids']]).to(device)\n",
            "/var/folders/37/x82lvgr524l4fd08t3g06rl40000gn/T/ipykernel_20874/1704487477.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  attention_mask = torch.stack([torch.tensor(item) for item in batch['attention_mask']]).to(device)\n",
            "/var/folders/37/x82lvgr524l4fd08t3g06rl40000gn/T/ipykernel_20874/1704487477.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  token_type_ids = torch.stack([torch.tensor(item) for item in batch['token_type_ids']]).to(device)\n",
            "Evaluating Accuracy:   0%|          | 2/1094 [01:29<13:43:42, 45.26s/it]wandb-core(22193) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "Evaluating Accuracy:   0%|          | 3/1094 [02:15<13:43:17, 45.28s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[106], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Use it like this (you can optionally specify device if needed)\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtuned_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Automatically detects device\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[106], line 37\u001b[0m, in \u001b[0;36mcalculate_accuracy\u001b[0;34m(model, dataloader, device)\u001b[0m\n\u001b[1;32m     30\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: input_ids,\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: attention_mask,\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: token_type_ids\n\u001b[1;32m     34\u001b[0m }\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 37\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# Ensure predictions are properly shaped\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1665\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1657\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1658\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1659\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1660\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1661\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1662\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1663\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1665\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1672\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1673\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1675\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1677\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1679\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    686\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         output_attentions,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:627\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    624\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    625\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 627\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/pytorch_utils.py:255\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:640\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m    639\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 640\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    552\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[1;32m    553\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m--> 554\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLayerNorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/normalization.py:217\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/functional.py:2900\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2892\u001b[0m         layer_norm,\n\u001b[1;32m   2893\u001b[0m         (\u001b[38;5;28minput\u001b[39m, weight, bias),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2898\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m   2899\u001b[0m     )\n\u001b[0;32m-> 2900\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2901\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2902\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def calculate_accuracy(model, dataloader, device=None):  \n",
        "    # Automatically choose the device if None\n",
        "    device = device or (\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.has_mps else \"cpu\")\n",
        "\n",
        "    # Make sure the model is on the correct device\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    all_predictions = []\n",
        "    all_true_labels = []\n",
        "    \n",
        "    # Using tqdm to track the progress during evaluation\n",
        "    for batch in tqdm(dataloader, desc=\"Evaluating Accuracy\", dynamic_ncols=True):\n",
        "        # Convert lists to tensors and handle batch dimension\n",
        "        input_ids = torch.stack([torch.tensor(item) for item in batch['input_ids']]).to(device)\n",
        "        attention_mask = torch.stack([torch.tensor(item) for item in batch['attention_mask']]).to(device)\n",
        "        token_type_ids = torch.stack([torch.tensor(item) for item in batch['token_type_ids']]).to(device)\n",
        "        \n",
        "        # Ensure labels are properly shaped\n",
        "        if isinstance(batch['labels'], torch.Tensor):\n",
        "            labels = batch['labels'].view(-1).to(device)  # Reshape to 1D\n",
        "        else:\n",
        "            labels = torch.tensor(batch['labels'], dtype=torch.long).view(-1).to(device)\n",
        "        \n",
        "        # Create inputs dictionary\n",
        "        inputs = {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'token_type_ids': token_type_ids\n",
        "        }\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            \n",
        "            # Ensure predictions are properly shaped\n",
        "            predictions = torch.argmax(logits, dim=-1)\n",
        "            \n",
        "            # Convert to numpy and append\n",
        "            all_predictions.extend(predictions.cpu().numpy().tolist())\n",
        "            all_true_labels.extend(labels.cpu().numpy().tolist())\n",
        "    \n",
        "    accuracy = accuracy_score(all_true_labels, all_predictions)\n",
        "    return accuracy\n",
        "\n",
        "# Use it like this (you can optionally specify device if needed)\n",
        "accuracy = calculate_accuracy(tuned_model, test_dataloader)  # Automatically detects device\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'tuned_model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 78\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cm\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Use it like this:\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m confusion_mat \u001b[38;5;241m=\u001b[39m calculate_confusion_matrix(\u001b[43mtuned_model\u001b[49m, test_dataloader)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tuned_model' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def calculate_confusion_matrix(model, dataloader, device=\"cpu\"):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_true_labels = []\n",
        "    \n",
        "    for batch in tqdm(dataloader, desc=\"Calculating Confusion Matrix\"):\n",
        "        # Convert lists to tensors and handle batch dimension\n",
        "        input_ids = torch.stack([torch.tensor(item) for item in batch['input_ids']]).to(device)\n",
        "        attention_mask = torch.stack([torch.tensor(item) for item in batch['attention_mask']]).to(device)\n",
        "        token_type_ids = torch.stack([torch.tensor(item) for item in batch['token_type_ids']]).to(device)\n",
        "        \n",
        "        # Ensure labels are properly shaped\n",
        "        if isinstance(batch['labels'], torch.Tensor):\n",
        "            labels = batch['labels'].view(-1).to(device)\n",
        "        else:\n",
        "            labels = torch.tensor(batch['labels'], dtype=torch.long).view(-1).to(device)\n",
        "        \n",
        "        # Create inputs dictionary\n",
        "        inputs = {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'token_type_ids': token_type_ids\n",
        "        }\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            predictions = torch.argmax(logits, dim=-1)\n",
        "            \n",
        "            all_predictions.extend(predictions.cpu().numpy().tolist())\n",
        "            all_true_labels.extend(labels.cpu().numpy().tolist())\n",
        "    \n",
        "    # Calculate confusion matrix\n",
        "    cm = confusion_matrix(all_true_labels, all_predictions)\n",
        "    \n",
        "    # Create labels for the classes\n",
        "    labels = ['Negative', 'Positive']\n",
        "    \n",
        "    # Create and display confusion matrix\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "    disp.plot(cmap='Blues', values_format='d')\n",
        "    plt.title('Confusion Matrix')\n",
        "    \n",
        "    # Add text annotations with percentages\n",
        "    total = np.sum(cm)\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            percentage = cm[i, j] / total * 100\n",
        "            plt.text(j, i, f'\\n{percentage:.1f}%', \n",
        "                    ha='center', va='center')\n",
        "    \n",
        "    # Calculate and print additional metrics\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "    \n",
        "    print(\"\\nDetailed Metrics:\")\n",
        "    print(f\"True Negatives: {tn}\")\n",
        "    print(f\"False Positives: {fp}\")\n",
        "    print(f\"False Negatives: {fn}\")\n",
        "    print(f\"True Positives: {tp}\")\n",
        "    print(f\"\\nPrecision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1_score:.4f}\")\n",
        "    \n",
        "    plt.show()\n",
        "    return cm\n",
        "\n",
        "# Use it like this:\n",
        "confusion_mat = calculate_confusion_matrix(tuned_model, test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WS7CxKTtkIsM"
      },
      "outputs": [],
      "source": [
        "\n",
        "# use pipeline for prediciton\n",
        "from transformers import pipeline\n",
        "classifier = pipeline('text-classification', model= 'bert-base-uncased-sentiment-model')\n",
        "classifier([text, 'A very good day indeed', \"We loved mth111\", \"I am feeling anxious\"])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0027ab7df76e4434af60ec9a53ba8a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "022f5dae33c14d0f877912a5dbbe13b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "048c7f91bc274f8bb0ec7a69533739a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_904cd907b85749f48e50ed8595c19342",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffd6b6f83e3543419902fa503e8840ab",
            "value": 5000
          }
        },
        "07a6c9c54b0f4c1089ac3c2cb4a0a3de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68ced9ee07664ae3bdd7e7952d098f7b",
            "placeholder": "​",
            "style": "IPY_MODEL_0027ab7df76e4434af60ec9a53ba8a45",
            "value": "Map: 100%"
          }
        },
        "1b999f2e4f23449c8e9ecd68a04c927a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "381e37e909ce4b9dad342e0d496b0b35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75bb5e0ea62f43bf87b961c6d6499c95",
              "IPY_MODEL_048c7f91bc274f8bb0ec7a69533739a6",
              "IPY_MODEL_3e5f83568dbf4e9a854b5cf28e90fccf"
            ],
            "layout": "IPY_MODEL_022f5dae33c14d0f877912a5dbbe13b0"
          }
        },
        "3e5f83568dbf4e9a854b5cf28e90fccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3fd3ebca83a454b9084de729b6ca644",
            "placeholder": "​",
            "style": "IPY_MODEL_1b999f2e4f23449c8e9ecd68a04c927a",
            "value": " 5000/5000 [00:05&lt;00:00, 868.17 examples/s]"
          }
        },
        "427a50b2b4a74b61b45d8d8b05b5d3ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58a5ac485ab8430b800e7074514a20f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "596b48836576428ca40560e7f929b714": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a8973980d9146828d52e5a1b3cbac9e",
            "placeholder": "​",
            "style": "IPY_MODEL_ab8b099771cb4308b45fb68400842b14",
            "value": " 35000/35000 [00:28&lt;00:00, 1241.26 examples/s]"
          }
        },
        "5c9b2069c2944482b266e9978b446a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07a6c9c54b0f4c1089ac3c2cb4a0a3de",
              "IPY_MODEL_d03e1b7428924223989a4165677942c6",
              "IPY_MODEL_df86635c6c114aa18764faaa03a8a321"
            ],
            "layout": "IPY_MODEL_8df3aa8f8f094a0c857a596a2cc61e84"
          }
        },
        "5f98a7d1a14749e4abcd84bd28cafe59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce54aca5b5e3479c8757f82e65369c79",
            "placeholder": "​",
            "style": "IPY_MODEL_d4749681d1e54c6daffeaf0b977dfbde",
            "value": "Map: 100%"
          }
        },
        "675bd947ecfc4e3c865d316a9ce9a448": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68ced9ee07664ae3bdd7e7952d098f7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f48f6474c2f4a6ebf88ae8258ea6d94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75bb5e0ea62f43bf87b961c6d6499c95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58a5ac485ab8430b800e7074514a20f9",
            "placeholder": "​",
            "style": "IPY_MODEL_96b6d705b60c43f2881f67e3eba2f9c4",
            "value": "Map: 100%"
          }
        },
        "805fc0b3514a48a8811fc5ad229f87aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f98a7d1a14749e4abcd84bd28cafe59",
              "IPY_MODEL_bec587eadac44b07866904a981251210",
              "IPY_MODEL_596b48836576428ca40560e7f929b714"
            ],
            "layout": "IPY_MODEL_913e29c4bdc84de2be0fb22739ba3477"
          }
        },
        "8df3aa8f8f094a0c857a596a2cc61e84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "904cd907b85749f48e50ed8595c19342": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "913e29c4bdc84de2be0fb22739ba3477": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "954a1e50c02644ddb173bd08c0dff0f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96b6d705b60c43f2881f67e3eba2f9c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a8973980d9146828d52e5a1b3cbac9e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f7996cdd55e400ba9a9ad6652b551b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab8b099771cb4308b45fb68400842b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad856b0331c44d8387d3fe3959022047": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3fd3ebca83a454b9084de729b6ca644": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bec587eadac44b07866904a981251210": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f7996cdd55e400ba9a9ad6652b551b9",
            "max": 35000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_954a1e50c02644ddb173bd08c0dff0f6",
            "value": 35000
          }
        },
        "ce54aca5b5e3479c8757f82e65369c79": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d03e1b7428924223989a4165677942c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad856b0331c44d8387d3fe3959022047",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_675bd947ecfc4e3c865d316a9ce9a448",
            "value": 10000
          }
        },
        "d4749681d1e54c6daffeaf0b977dfbde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df86635c6c114aa18764faaa03a8a321": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_427a50b2b4a74b61b45d8d8b05b5d3ad",
            "placeholder": "​",
            "style": "IPY_MODEL_6f48f6474c2f4a6ebf88ae8258ea6d94",
            "value": " 10000/10000 [00:11&lt;00:00, 841.38 examples/s]"
          }
        },
        "ffd6b6f83e3543419902fa503e8840ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
